{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning on Our DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import merge, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down_left\n",
      "Loaded the images of dataset-down_left\n",
      "\n",
      "200\n",
      "down_right\n",
      "Loaded the images of dataset-down_right\n",
      "\n",
      "400\n",
      "up_left\n",
      "Loaded the images of dataset-up_left\n",
      "\n",
      "600\n",
      "up_right\n",
      "Loaded the images of dataset-up_right\n",
      "\n",
      "800\n",
      "(800, 1, 224, 224, 3)\n",
      "(1, 800, 224, 224, 3)\n",
      "(800, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading the training data\n",
    "data_path = r'E:/surbhi/phd/Sem2/ML/code/dataset'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_data_list=[]\n",
    "j=0\n",
    "for dataset in data_dir_list:\n",
    "    print(dataset)\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    i=1\n",
    "\n",
    "    for img in img_list:\n",
    "        if i<=200:\n",
    "            img_path = data_path + '/'+ dataset + '/'+ img\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            x = image.img_to_array(img)\n",
    "            #print(x,x.shape)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            #print('xp ',x,x.shape)\n",
    "            x = preprocess_input(x)\n",
    "            x = x/255\n",
    "            img_data_list.append(x)\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "        j+=1\n",
    "    print(j)\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "#img_data = img_data.astype('float32')\n",
    "print (img_data.shape)\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "print (img_data.shape)\n",
    "img_data=img_data[0]\n",
    "print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 224, 224, 3) (160, 224, 224, 3) (640, 4) (160, 4)\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:200]=0    #down left\n",
    "labels[200:400]=1  #down_right\n",
    "labels[400:600]=2  #up_left\n",
    "labels[600:]=3     #up_right\n",
    "\n",
    "names = ['DL','DR','UL','UR']\n",
    "\n",
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "tf_model = VGG16(input_tensor=image_input,include_top=True)\n",
    "print(tf_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changed model (last dense layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 17,960,132\n",
      "Trainable params: 17,960,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "last_layer = tf_model.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "dense1 = Dense(128, activation='relu', name='dense1')(x)\n",
    "dense2 = Dense(256, activation='relu', name='dense2')(dense1)\n",
    "out = Dense(4, activation='softmax', name='output')(dense2)\n",
    "\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in custom_vgg_model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "custom_vgg_model.layers[3].trainable\n",
    "\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/20\n",
      "640/640 [==============================] - 282s 440ms/step - loss: 1.0241 - acc: 0.6094 - val_loss: 0.4936 - val_acc: 0.7937\n",
      "Epoch 2/20\n",
      "640/640 [==============================] - 277s 432ms/step - loss: 0.3555 - acc: 0.8516 - val_loss: 0.4100 - val_acc: 0.8562\n",
      "Epoch 3/20\n",
      "640/640 [==============================] - 274s 428ms/step - loss: 0.1829 - acc: 0.9344 - val_loss: 0.2445 - val_acc: 0.9062\n",
      "Epoch 4/20\n",
      "640/640 [==============================] - 275s 429ms/step - loss: 0.1163 - acc: 0.9547 - val_loss: 0.2135 - val_acc: 0.9000\n",
      "Epoch 5/20\n",
      "640/640 [==============================] - 274s 429ms/step - loss: 0.0686 - acc: 0.9781 - val_loss: 0.2113 - val_acc: 0.9187\n",
      "Epoch 6/20\n",
      "640/640 [==============================] - 276s 431ms/step - loss: 0.0616 - acc: 0.9812 - val_loss: 0.3579 - val_acc: 0.8625\n",
      "Epoch 7/20\n",
      "640/640 [==============================] - 275s 430ms/step - loss: 0.0536 - acc: 0.9812 - val_loss: 0.1789 - val_acc: 0.9250\n",
      "Epoch 8/20\n",
      "640/640 [==============================] - 275s 429ms/step - loss: 0.0358 - acc: 0.9922 - val_loss: 0.3635 - val_acc: 0.9125\n",
      "Epoch 9/20\n",
      "640/640 [==============================] - 276s 431ms/step - loss: 0.0451 - acc: 0.9922 - val_loss: 0.2813 - val_acc: 0.8812\n",
      "Epoch 10/20\n",
      "640/640 [==============================] - 276s 432ms/step - loss: 0.0444 - acc: 0.9812 - val_loss: 0.3047 - val_acc: 0.8938\n",
      "Epoch 11/20\n",
      "640/640 [==============================] - 279s 436ms/step - loss: 0.0298 - acc: 0.9922 - val_loss: 0.2159 - val_acc: 0.9187\n",
      "Epoch 12/20\n",
      "640/640 [==============================] - 274s 429ms/step - loss: 0.0223 - acc: 0.9953 - val_loss: 0.2858 - val_acc: 0.9250\n",
      "Epoch 13/20\n",
      "640/640 [==============================] - 278s 435ms/step - loss: 0.0198 - acc: 0.9937 - val_loss: 0.3044 - val_acc: 0.8938\n",
      "Epoch 14/20\n",
      "640/640 [==============================] - 278s 435ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9187\n",
      "Epoch 15/20\n",
      "640/640 [==============================] - 275s 429ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9187\n",
      "Epoch 16/20\n",
      "640/640 [==============================] - 276s 431ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.2090 - val_acc: 0.9250\n",
      "Epoch 17/20\n",
      "640/640 [==============================] - 275s 430ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2086 - val_acc: 0.9313\n",
      "Epoch 18/20\n",
      "640/640 [==============================] - 273s 426ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1924 - val_acc: 0.9250\n",
      "Epoch 19/20\n",
      "640/640 [==============================] - 275s 430ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9313\n",
      "Epoch 20/20\n",
      "640/640 [==============================] - 276s 431ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.2000 - val_acc: 0.9313\n"
     ]
    }
   ],
   "source": [
    "hist = custom_vgg_model.fit(X_train, y_train, batch_size=32, epochs=20, verbose=1, validation_data=(X_test, y_test))\n",
    "fname = 'tfvggweight3.hdf5'\n",
    "model_json = custom_vgg_model.to_json()\n",
    "with open(\"tfvggmodel3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "custom_vgg_model.save_weights(fname,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual O/P: dl1 (1).jpg\n",
      "[0]\n",
      "Actual O/P: dl1 (2).jpg\n",
      "[0]\n",
      "Actual O/P: dl1 (3).jpg\n",
      "[0]\n",
      "Actual O/P: dl1 (4).jpg\n",
      "[0]\n",
      "Actual O/P: dl1 (5).jpg\n",
      "[0]\n",
      "Actual O/P: dr (1).jpg\n",
      "[1]\n",
      "Actual O/P: dr (2).jpg\n",
      "[1]\n",
      "Actual O/P: dr (3).jpg\n",
      "[1]\n",
      "Actual O/P: dr (4).jpg\n",
      "[1]\n",
      "Actual O/P: i l.jfif\n",
      "[1]\n",
      "Actual O/P: ul (1).jpg\n",
      "[2]\n",
      "Actual O/P: ul (2).jpg\n",
      "[2]\n",
      "Actual O/P: ul (3).jpg\n",
      "[1]\n",
      "Actual O/P: ul (4).jpg\n",
      "[2]\n",
      "Actual O/P: ur (1).jpg\n",
      "[3]\n",
      "Actual O/P: ur (2).jpg\n",
      "[3]\n",
      "Actual O/P: ur (3).jpg\n",
      "[3]\n",
      "Actual O/P: ur (4).jpg\n",
      "[3]\n",
      "Actual O/P: ur5.jfif\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import cv2\n",
    "import os\n",
    "def predict():\n",
    "    json_file = open('tfvggmodel3.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "\n",
    "    model.load_weights('tfvggweight3.hdf5')\n",
    "    #print(model.summary())\n",
    "    path=r'E:/surbhi/phd/Sem2/ML/code/test'\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        print('Actual O/P:',file)\n",
    "        img=cv2.imread(os.path.join(path,file))\n",
    "        img=cv2.resize(img,(224,224))\n",
    "        #print(img.shape)\n",
    "        img = img.reshape(1, 224,224,3)\n",
    "        #print(img.shape)\n",
    "        img = img.astype('float32')\n",
    "        img =img / 255\n",
    "        y_proba = model.predict(img)\n",
    "        y_classes = y_proba.argmax(axis=-1)\n",
    "        print(y_classes)\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
